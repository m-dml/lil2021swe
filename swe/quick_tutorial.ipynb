{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick tutorial to implicit neural emulators\n",
    "\n",
    "- We load a dataset (integration step-size dt=900) and a pre-trained implicit model and use it to generate a simulation.\n",
    "- We have a look at the learned systems of linear equations of the implicit model (defined by tensors M,b).\n",
    "- We check convergence of the Red-Black Gauss-Seidel solver in a typical forward- and backward-pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from implem.utils import init_torch_device, as_tensor, device, dtype, dtype_np\n",
    "from implem.model import LightningImplicitModel, LightningImplicitPretrainModel\n",
    "\n",
    "swe_model = '2D'\n",
    "assert swe_model in ['1D', '2D']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data loading / formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from src.train import load_data_swe\n",
    "from implem.data import MultiStepMultiTrialDataset\n",
    "\n",
    "data, data_descr, n_static_channels, data_scales = load_data_swe(\n",
    "    filedir='./data', \n",
    "    data_fn='dataset_dt900',\n",
    "    instance_dimensionality=swe_model, normalize_channels=True)\n",
    "\n",
    "from implem.data import DataModule\n",
    "\n",
    "offset = np.arange(1) + 1\n",
    "batch_size = 16\n",
    "\n",
    "dm = DataModule(data=data, batch_size = batch_size, offset = offset, Dataset = MultiStepMultiTrialDataset)\n",
    "dm.setup()\n",
    "\n",
    "for batch in dm.train_dataloader():\n",
    "    x,y = batch\n",
    "    print('example input- and output tensor shapes:', (x.shape, y.shape))\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implem.model import LightningImplicitModel, ImplicitLayer\n",
    "import hydra\n",
    "from omegaconf import read_write\n",
    "\n",
    "from src.utils import fix_bM_BCs, enforce_bcs, network_init_swe\n",
    "\n",
    "with hydra.initialize(config_path='configs'):\n",
    "    cfg = hydra.compose(config_name='defaults.yaml', overrides=[f\"data=swe{swe_model}\", \"model=model_implicit\"])\n",
    "\n",
    "model = hydra.utils.instantiate(\n",
    "        cfg.model,\n",
    "        instance_dimensionality = cfg.data.instance_dimensionality,\n",
    "        input_channels = data.shape[2],\n",
    "        static_channels = n_static_channels, # do not predict channels that do not change over time\n",
    "        offset = [1],                        # how many steps into future to predict \n",
    "        system_determ=[fix_bM_BCs, None],    # enforce BCs on system of linear equations\n",
    "        format_output = enforce_bcs,         # enforce BCs on velocities\n",
    "        _recursive_ = False # necessary for model.configure_optimizers()\n",
    ")\n",
    "\n",
    "# initialize model: fix some layers to ensure output of linear solve is water height.\n",
    "network_init_swe(model, x, data_scales, dt=300., dx=1e4, w_imp=0.5, g=9.81, cd=1e-3, ah=1e3)\n",
    "\n",
    "t_start = -2\n",
    "x = as_tensor(data[0, t_start]).unsqueeze(0)\n",
    "print(model.forward(x).shape)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from omegaconf import OmegaConf\n",
    "from os import listdir\n",
    "\n",
    "\n",
    "train_in_notebook = False\n",
    "\n",
    "\n",
    "if train_in_notebook:\n",
    "\n",
    "    # if the model is trained on GPU add a GPU logger to see GPU utilization in comet-ml logs:\n",
    "    GPUS = 1\n",
    "    if GPUS < 1:\n",
    "        callbacks = None\n",
    "    else:\n",
    "        callbacks = [\n",
    "            pl.callbacks.EarlyStopping(monitor='loss/val', patience=50),\n",
    "        ]\n",
    "\n",
    "    logger_tb = pl.loggers.TensorBoardLogger(\".\", \"\", \"\", \n",
    "                                             log_graph=True, \n",
    "                                             default_hp_metric=False)\n",
    "    trainer = pl.Trainer(**OmegaConf.to_container(cfg.trainer),\n",
    "                         logger=logger_tb, \n",
    "                         callbacks=callbacks)\n",
    "    trainer.fit(model, dm)\n",
    "\n",
    "else:\n",
    "\n",
    "    # load provided implicit model for integration step-size dt = 900.  \n",
    "    model_str = 'SWE2D_dt900/ImplicitModel/min_net0/2021-09-20_135046/'\n",
    "\n",
    "    fls = listdir(f\"outputs/{model_str}checkpoints/\")\n",
    "    with hydra.initialize(config_path=f\"outputs/{model_str}hydra/\"):\n",
    "        cfg = hydra.compose(config_name='config.yaml')\n",
    "    print('cfg', cfg)\n",
    "        \n",
    "    model = LightningImplicitModel.load_from_checkpoint(\n",
    "        checkpoint_path=f\"outputs/{model_str}checkpoints/\" + fls[-1], \n",
    "        **cfg['model'], \n",
    "        instance_dimensionality = cfg.data.instance_dimensionality,\n",
    "        input_channels=data.shape[2],\n",
    "        static_channels = n_static_channels,\n",
    "        offset = offset,\n",
    "        system_determ=[fix_bM_BCs, None],\n",
    "        format_output = enforce_bcs,\n",
    "    )\n",
    "    print('model', model)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model evualtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model simulation from selected datapoint in dataset to compare against true trajectory\n",
    "\n",
    "n, t_start, t_end = -1, 20, 101 # trial, starting step, stopping step\n",
    "\n",
    "out = []\n",
    "with torch.no_grad():\n",
    "    for t in range(t_end-t_start-1):\n",
    "        if t == 0:\n",
    "            x = as_tensor(data[n, t_start+t]).unsqueeze(0)\n",
    "            out.append(x[0,:-n_static_channels].unsqueeze(0))\n",
    "        else:\n",
    "            x = torch.cat((out[-1][0], as_tensor(data[n, t_start][-n_static_channels:])), dim=0).unsqueeze(0)\n",
    "\n",
    "        x_est = model(x)\n",
    "        out.append(x_est)\n",
    "\n",
    "out = torch.cat(out, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a few snapshots for comparison\n",
    "\n",
    "from src.utils import plot_results_swe\n",
    "i = 0\n",
    "plot_results_swe(data_numerical=data[n,t_start:t_end:,i,:], \n",
    "                 data_model=out[:,i,:].cpu().numpy(), \n",
    "                 i=i, swe_model=swe_model, if_save=False, fig_path=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare maps of learned with true stencils for this problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from src.utils import swe2D_true_bM\n",
    "\n",
    "dt = 900. # time step [s]\n",
    "dx = 1e4 # grid spacing [m]\n",
    "g = 9.81\n",
    "w_imp = 0.5\n",
    "cd = 1e-3\n",
    "ah = 1000.\n",
    "\n",
    "n, t_start = 50, -2\n",
    "\n",
    "# true stencils\n",
    "x = as_tensor(data[n, t_start]).unsqueeze(0)\n",
    "b_true, M_true, us, vs = swe2D_true_bM(x, dt, dx, g, w_imp, cd, ah, data_scales, comp_u='calculate')\n",
    "\n",
    "plt.figure(figsize=(16,5))\n",
    "plt.imshow(b_true[0,0].detach().cpu().numpy().T)\n",
    "print(b_true[0,0][1:-1,1:-1].detach().cpu().numpy().mean())\n",
    "plt.title('right-handside b')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "for i in range(M_true.shape[2]):\n",
    "    plt.figure(figsize=(16,5))\n",
    "    plt.title(r'tensor $\\left(M_\\phi\\right)_{c}$' + f', c = ' + str(i+1))\n",
    "    plt.imshow(M_true[0,0,i].detach().cpu().numpy().T)\n",
    "    print(M_true[0,0,i][1:-1,1:-1].detach().cpu().numpy().mean())\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# learned stencils\n",
    "\n",
    "x = as_tensor(data[n, t_start]).unsqueeze(0)\n",
    "model = model.to(device)\n",
    "M, b, _ = model.impl_layers[0]._forward(x)\n",
    "\n",
    "plt.figure(figsize=(16,5))\n",
    "plt.imshow(b[0,0].detach().cpu().numpy().T)\n",
    "plt.title('right-handside b')\n",
    "print(b[0,0][1:-1,1:-1].detach().cpu().numpy().mean())\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "for i in range(5):\n",
    "    plt.figure(figsize=(16,5))\n",
    "    plt.imshow(M[0,0,i].detach().cpu().numpy().T)\n",
    "    plt.title(r'tensor $\\left(M_\\phi\\right)_{c}$' + f', c = ' + str(i+1))\n",
    "    print(M[0,0,i][1:-1,1:-1].detach().cpu().numpy().mean())\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convergence of forward-pass for learned (M,b) and example x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implem.utils import transpose_compact_blockmat, transpose_compact_blockmat_sep_eqs_per_field\n",
    "from implem.utils import banded_gauss_seidel_redblack, biCGstab_l\n",
    "\n",
    "settings = model.impl_layers[0].settings\n",
    "\n",
    "settings['thresh'] = 1e-15 # for training we use 1e-14\n",
    "settings['max_iter'] = 50\n",
    "\n",
    "with torch.no_grad():\n",
    "    settings['x_init'] = 1.* x[:,:1]\n",
    "    z, diagnostics = banded_gauss_seidel_redblack(M, b,\n",
    "                                        **settings)\n",
    "    settings['x_init'] = None\n",
    "\n",
    "plt.semilogy(diagnostics[:,0,0].detach().cpu().numpy())\n",
    "plt.ylabel('MSE on |Az-b|')\n",
    "plt.xlabel('Red-Black Gauss-Seidel iterations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convergence of backward-pass solve for learned (M,b) and example x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implem.utils import transpose_compact_blockmat, transpose_compact_blockmat_sep_eqs_per_field\n",
    "from implem.utils import banded_gauss_seidel_redblack, biCGstab_l\n",
    "\n",
    "x = as_tensor(data[n, t_start]).unsqueeze(0)\n",
    "z = model.impl_layers[0].forward(x).detach()\n",
    "z.requires_grad = True\n",
    "pred = model.impl_layers[1].forward(z)\n",
    "y = as_tensor(data[n, t_start])[:-n_static_channels].unsqueeze(0)\n",
    "\n",
    "loss_function = torch.nn.MSELoss()\n",
    "loss = loss_function(input=pred, target=y)\n",
    "loss.backward()\n",
    "\n",
    "dLdz = z.grad[:,:1]\n",
    "\n",
    "settings = model.impl_layers[0].settings\n",
    "\n",
    "settings['thresh'] = 1e-25 # for training we use 1e-24\n",
    "settings['max_iter'] = 50\n",
    "\n",
    "if settings['sep_eqs_per_field']:\n",
    "    transpose_M = transpose_compact_blockmat_sep_eqs_per_field\n",
    "    start_flatten_dim_M = 3 # M.shape = (N, L, K, *spatial_dims)\n",
    "else:\n",
    "    transpose_M = transpose_compact_blockmat\n",
    "    start_flatten_dim_M = 4 # M.shape = (N, L, L, K, *spatial_dims)\n",
    "\n",
    "MT = transpose_M(M.flatten(start_dim=start_flatten_dim_M),\n",
    "                         offdiagonals=settings['offdiagonals']).reshape(M.shape)\n",
    "\n",
    "with torch.no_grad():\n",
    "    settings['x_init'] = torch.zeros_like(dLdz)\n",
    "    settings['x_init'] = torch.nn.functional.pad(input = settings['x_init'], \n",
    "                                                         pad = settings['pad_x_backward_init'])\n",
    "    z, diagnostics = banded_gauss_seidel_redblack(MT, dLdz,\n",
    "                                **settings)\n",
    "    settings['x_init'] = None\n",
    "\n",
    "plt.semilogy(diagnostics[:,0,0].detach().cpu().numpy())\n",
    "plt.ylabel('MSE on |Az-b|')\n",
    "plt.xlabel('Red-Black Gauss-Seidel iterations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
